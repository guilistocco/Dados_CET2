{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "\n",
    "num_agrupado =[\"10588\",\"10613\",\"10613\",\"10619\",\"10622\",\"10632\",\"10632\",\"10634\",\"10634\",\"10652\",\"10652\",\"10667\",\"10667\",\"10516\",\"10528\",\"10528\",\"10554\",\"10605\",\"10637\",\"10637\",\"10637\",\"10644\",\"10644\",\"10644\",\"10644\",\"10488\",\"10488\",\"10509\",\"10509\",\"10556\",\"10556\",\"10557\",\"10557\",\"10594\",\"10594\",\"10595\",\"10595\",\"10679\",\"10679\",\"10680\",\"10680\",\"10748\",\"10748\",\"10761\",\"10761\",\"10426\",\"10426\",\"10426\",\"10433\",\"10433\",\"10433\",\"10433\",\"10482\",\"10482\",\"10482\",\"10482\",\"10484\",\"10484\",\"10484\",\"10492\",\"10492\",\"10500\",\"10507\",\"10521\",\"10527\",\"10527\",\"10531\",\"10531\"]\n",
    "\n",
    "\n",
    "Radares = [5415,5483,5126,5471,5470,5316,5315,5313,5314,5358,5357,5355,5356,5463,5297,5296,5354,5098,5476,5475,5474,5479,5478,5477,5480,5323,5226,5308,5307,5432,5433,5414,5413,5201,5200,5199,5198,5205,5204,5203,5202,5196,5197,5195,5194,5445,5104,5446,5103,5462,5461,5460,5441,5106,5443,5442,5439,5105,5440,5457,5449,5317,5101,5506,5336,5335,5402,5401]\n",
    "\n",
    "\n",
    "# cria um dicionário\n",
    "def faz_dict (keys, values):\n",
    "    '''\n",
    "        Cria um dicionário com a correspondência entre \n",
    "        chaves e valores. Com a função .map() pode, ser\n",
    "        adicionadas novas colunas no DF.\n",
    "\n",
    "        Inputs:\n",
    "            keys: (list) chaves que estão no presente DF\n",
    "            values: (list) valores que serão inputados na nova coluna\n",
    "\n",
    "        Return:\n",
    "            mapa: (dict) mapa de correspondência\n",
    "    '''\n",
    "\n",
    "    mapa = {}\n",
    "    for i in range(len(keys)):\n",
    "        mapa[keys[i]] = values[i]\n",
    "\n",
    "    return mapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "estacoes = [\"BT\",\"BT\",\"BT\",\"BT\",\"BT\",\"BT\",\"BT\",\"BT\",\"BT\",\"BT\",\"BT\",\"BT\",\"BT\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"VM\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"CGE\",\"IP\",\"IP\",\"IP\",\"IP\",\"IP\",\"IP\",\"IP\",\"IP\",\"IP\",\"IP\",\"IP\",\"IP\",\"IP\",\"IP\",\"IP\",\"IP\",\"IP\",\"IP\",\"IP\",\"IP\",\"IP\",\"IP\",\"JB\",\"JB\",\"JB\",\"JB\",\"JB\",\"JB\",\"JB\",\"JB\",\"JB\",\"JB\",\"LP\",\"LP\",\"LP\",\"LP\",\"LP\",\"LP\",\"LP\",\"LP\",\"LP\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"PI\",\"SA\",\"SA\",\"SA\",\"SA\",\"SA\",\"SA\",\"SA\",\"SA\",\"SA\",\"SA\",\"SA\",\"SA\",\"SA\",\"SA\",\"SA\",\"SA\",\"SA\",\"SA\",\"SA\",\"SA\",\"SA\",\"SA\",\"SA\",\"ST\",\"ST\",\"ST\",\"ST\",\"ST\",\"ST\",\"ST\",\"ST\",\"ST\",\"ST\",\"ST\",\"ST\",\"ST\",\"ST\",\"ST\",\"ST\",\"ST\",\"ST\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\",\"VM\"]\n",
    "\n",
    "numeros_agrupados = [\"10875\",\"10862\",\"10874\",\"10858\",\"10858\",\"10893\",\"10893\",\"10864\",\"10848\",\"10906\",\"10900\",\"10904\",\"10905\",\"10605\",\"10433\",\"10426\",\"10468\",\"10508\",\"10508\",\"10613\",\"10538\",\"10616\",\"10631\",\"10505\",\"10533\",\"10607\",\"10524\",\"10479\",\"10565\",\"10586\",\"10583\",\"10587\",\"10587\",\"10584\",\"10584\",\"10514\",\"10514\",\"10513\",\"10513\",\"10595\",\"10595\",\"10594\",\"10594\",\"10582\",\"10582\",\"10585\",\"10585\",\"10555\",\"10552\",\"10488\",\"10615\",\"10464\",\"10560\",\"10543\",\"10543\",\"10540\",\"10542\",\"10512\",\"10509\",\"10509\",\"10438\",\"10497\",\"10532\",\"10532\",\"10488\",\"10502\",\"10459\",\"10454\",\"10480\",\"10591\",\"10540\",\"10591\",\"10520\",\"10554\",\"10590\",\"10537\",\"10609\",\"10609\",\"10506\",\"10506\",\"10490\",\"10490\",\"10557\",\"10557\",\"10517\",\"10556\",\"10556\",\"10426\",\"10426\",\"10568\",\"10596\",\"10596\",\"10433\",\"10433\",\"10433\",\"10628\",\"10622\",\"10619\",\"10613\",\"10538\",\"10616\",\"10468\",\"10476\",\"10476\",\"10276\",\"10306\",\"10305\",\"10348\",\"10348\",\"10337\",\"10337\",\"10309\",\"10309\",\"10310\",\"10310\",\"10302\",\"10302\",\"10293\",\"10352\",\"10262\",\"10262\",\"10353\",\"10235\",\"10269\",\"10291\",\"10292\",\"10434\",\"10434\",\"10408\",\"10371\",\"10368\",\"10380\",\"10381\",\"10434\",\"10381\",\"10381\",\"10933\",\"10940\",\"10881\",\"10877\",\"10947\",\"10911\",\"10933\",\"10894\",\"10895\",\"10770\",\"10725\",\"10655\",\"10655\",\"10702\",\"10702\",\"10701\",\"10701\",\"10630\",\"10630\",\"10674\",\"10675\",\"10670\",\"10656\",\"10654\",\"10654\",\"10720\",\"10692\",\"10732\",\"10684\",\"10709\",\"10672\",\"10788\",\"10715\",\"10807\",\"10807\",\"10683\",\"10683\",\"10762\",\"10762\",\"10834\",\"10834\",\"10761\",\"10761\",\"10748\",\"10748\",\"10680\",\"10680\",\"10679\",\"10679\",\"10635\",\"10635\",\"10808\",\"10658\",\"10664\",\"10653\",\"10820\",\"10815\",\"10815\",\"10724\",\"10713\",\"10712\",\"10711\",\"10810\",\"10689\",\"10634\",\"10634\",\"10632\",\"10632\",\"10745\",\"10800\",\"10800\",\"10670\",\"10689\",\"10742\",\"10742\",\"10747\",\"10747\",\"10798\",\"10798\",\"10665\",\"10665\",\"10830\",\"10667\",\"10667\",\"10652\",\"10652\",\"10669\",\"10669\",\"10698\",\"10698\",\"10697\",\"10697\",\"10640\",\"10640\",\"10686\",\"10686\",\"10736\",\"10736\",\"10731\",\"10731\",\"10789\",\"10703\",\"10829\",\"10729\",\"10656\",\"10764\",\"10678\",\"10763\",\"10637\",\"10637\",\"10637\",\"10644\",\"10644\",\"10644\",\"10644\",\"10658\",\"10767\",\"10704\",\"10673\",\"10627\",\"10627\",\"10625\",\"10625\",\"10592\",\"10592\",\"10578\",\"10578\",\"10650\",\"10527\",\"10527\",\"10534\",\"10474\",\"10474\",\"10471\",\"10471\",\"10531\",\"10531\",\"10589\",\"10511\",\"10511\",\"10521\",\"10623\",\"10564\",\"10564\",\"10614\",\"10614\",\"10577\",\"10577\",\"10536\",\"10620\",\"10620\",\"10477\",\"10498\",\"10498\",\"10526\",\"10526\",\"10588\",\"10530\",\"10536\",\"10645\",\"10325\",\"10323\",\"10507\",\"10356\",\"10484\",\"10482\",\"10277\",\"10431\",\"10478\",\"10606\",\"10606\",\"10539\",\"10539\",\"10487\",\"10452\",\"10458\",\"10475\",\"10384\",\"10374\",\"10566\",\"10398\",\"10357\",\"10304\",\"10544\",\"10544\",\"10375\",\"10440\",\"10334\",\"10363\",\"10363\",\"10344\",\"10344\",\"10431\",\"10321\",\"10321\",\"10351\",\"10317\",\"10529\",\"10541\",\"10541\",\"10528\",\"10528\",\"10563\",\"10500\",\"10410\",\"10410\",\"10451\",\"10525\",\"10457\",\"10346\",\"10346\",\"10496\",\"10496\",\"10489\",\"10489\",\"10361\",\"10361\",\"10358\",\"10358\",\"10367\",\"10367\",\"10420\",\"10420\",\"10421\",\"10421\",\"10465\",\"10465\",\"10561\",\"10377\",\"10290\",\"10314\",\"10486\",\"10413\",\"10413\",\"10356\",\"10356\",\"10484\",\"10484\",\"10482\",\"10482\",\"10482\",\"10357\",\"10492\",\"10492\",\"10516\",\"10572\",\"10572\",\"10410\",\"10420\",\"10421\",\"10377\",\"10486\",\"10413\",\"10413\",\"10374\",\"10374\"]\n",
    "\n",
    "mapa_estacoes = faz_dict(numeros_agrupados, estacoes)\n",
    "# 0,L3,2018-02-28 23:56:22,5323,3,0,1095514,0,1,0,048,136,00649,84956\n",
    "# 54,L3,2018-08-03 00:00:12,5323,2,0,283530,0,1,0,118,053,03039,95040\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([\"P1\",\"P2\",\"P3\",\"P4\",\"P5\",\"P6\",\"P7\"])\n",
    "\n",
    "intervalos = pd.IntervalIndex.from_tuples([(0,5),(5,7),(7,10),(10,14),(14,17),(17,20),(20,24)], closed=\"left\")\n",
    "\n",
    "inter = [\"[0, 5)\",\"[5, 7)\",\"[7, 10)\",\"[10, 14)\",\"[14, 17)\",\"[17, 20)\",\"[20, 24)\"]\n",
    "# \"P1\",\"P2\",\"P3\",\"P4\",\"P5\",\"P6\",\"P7\"\n",
    "\n",
    "sentidos = [\"Sumare_N\",\"Sumare_S\",\"Sumare_S\",\"Sumare_S\",\"Sumare_N\",\"Sumare_N\",\"Sumare_N\",\"Sumare_S\",\"Sumare_S\",\"Sumare_S\",\"Sumare_S\",\"Sumare_N\",\"Sumare_N\",\"Brasil_N\",\"Brasil_S\",\"Brasil_S\",\"Brasil_S\",\"Brasil_S\",\"Brasil_S\",\"Brasil_S\",\"Brasil_S\",\"Brasil_N\",\"Brasil_N\",\"Brasil_N\",\"Brasil_N\",\"Reboucas_C\",\"Reboucas_C\",\"Reboucas_B\",\"Reboucas_B\",\"Reboucas_B\",\"Reboucas_B\",\"Reboucas_C\",\"Reboucas_C\",\"Reboucas_B\",\"Reboucas_B\",\"Reboucas_C\",\"Reboucas_C\",\"Reboucas_B\",\"Reboucas_B\",\"Reboucas_C\",\"Reboucas_C\",\"Reboucas_B\",\"Reboucas_B\",\"Reboucas_C\",\"Reboucas_C\",\"23deMaio_B\",\"23deMaio_B\",\"23deMaio_B\",\"23deMaio_C\",\"23deMaio_C\",\"23deMaio_C\",\"23deMaio_C\",\"23deMaio_C\",\"23deMaio_C\",\"23deMaio_C\",\"23deMaio_C\",\"23deMaio_B\",\"23deMaio_B\",\"23deMaio_B\",\"23deMaio_B\",\"23deMaio_B\",\"23deMaio_C\",\"23deMaio_B\",\"23deMaio_B\",\"23deMaio_B\",\"23deMaio_B\",\"23deMaio_C\",\"23deMaio_C\"]\n",
    "\n",
    "\n",
    "tip_faixa = [\"mista\",\"mista\",\"mista\",\"onibus\",\"mista\",\"mista\",\"mista\",\"mista\",\"onibus\",\"mista\",\"mista\",\"mista\",\"mista\",\"onibus\",\"mista\",\"mista\",\"mista\",\"mista\",\"onibus\",\"onibus\",\"mista\",\"mista\",\"mista\",\"mista\",\"mista\",\"mista\",\"mista\",\"mista\",\"mista\",\"mista\",\"mista\",\"onibus\",\"mista\",\"mista\",\"mista\",\"mista\",\"mista\",\"mista\",\"onibus\",\"mista\",\"mista\",\"onibus\",\"mista\",\"mista\",\"mista\",\"onibus\",\"mista\",\"mista\",\"mista\",\"onibus\",\"mista\",\"mista\",\"mista\",\"onibus\",\"mista\",\"mista\",\"mista\",\"onibus\",\"mista\",\"mista\",\"mista\",\"mista\",\"mista\",\"mista\",\"mista\",\"onibus\",\"mista\",\"mista\",\"onibus\",\"mista\",\"mista\",\"mista\",\"mista\",\"mista\",\"mista\",\"mista\",\"mista\",\"mista\",\"mista\",\"mista\",\"mista\",\"onibus\",\"mista\",\"mista\",\"onibus\",\"mista\",\"mista\",\"mista\",\"mista\",\"mista\",\"onibus\",\"mista\",\"mista\",\"mista\",\"mista\",\"mista\",\"mista\",\"mista\",\"mista\",\"mista\",\"mista\",\"mista\",\"mista\",\"mista\",\"mista\",\"mista\",\"onibus\",\"mista\",\"mista\",\"mista\",\"onibus\",\"onibus\",\"mista\",\"mista\",\"onibus\",\"mista\",\"mista\",\"onibus\",\"mista\",\"mista\",\"onibus\",\"mista\",\"mista\"]\n",
    "\n",
    "num_faixa = [\"104261\",\"104262\",\"104263\",\"104264\",\"104331\",\"104332\",\"104333\",\"104334\",\"104335\",\"104821\",\"104822\",\"104823\",\"104824\",\"104825\",\"104841\",\"104842\",\"104843\",\"104844\",\"104845\",\"104881\",\"104882\",\"104883\",\"104884\",\"104921\",\"104922\",\"104923\",\"105001\",\"105002\",\"105003\",\"105071\",\"105072\",\"105091\",\"105092\",\"105093\",\"105094\",\"105161\",\"105162\",\"105163\",\"105164\",\"105211\",\"105212\",\"105213\",\"105281\",\"105282\",\"105283\",\"105284\",\"105311\",\"105312\",\"105313\",\"105314\",\"105541\",\"105542\",\"105543\",\"105561\",\"105562\",\"105563\",\"105564\",\"105571\",\"105572\",\"105573\",\"105574\",\"105881\",\"105882\",\"105883\",\"105884\",\"105941\",\"105942\",\"105943\",\"105951\",\"105952\",\"105953\",\"106051\",\"106052\",\"106053\",\"106131\",\"106132\",\"106133\",\"106134\",\"106135\",\"106191\",\"106192\",\"106193\",\"106221\",\"106222\",\"106223\",\"106321\",\"106322\",\"106323\",\"106341\",\"106342\",\"106343\",\"106371\",\"106372\",\"106373\",\"106374\",\"106375\",\"106376\",\"106441\",\"106442\",\"106443\",\"106444\",\"106445\",\"106446\",\"106521\",\"106522\",\"106523\",\"106524\",\"106671\",\"106672\",\"106673\",\"106674\",\"106791\",\"106792\",\"106793\",\"106801\",\"106802\",\"106803\",\"107481\",\"107482\",\"107483\",\"107611\",\"107612\",\"107613\"]\n",
    "\n",
    "\n",
    "mapfaixas = faz_dict(num_faixa,tip_faixa)\n",
    "\n",
    "\n",
    "mapa_intervalos  = {}\n",
    "for i in range(len(labels)):\n",
    "    mapa_intervalos[inter[i]] = labels[i]\n",
    "\n",
    "\n",
    "\n",
    "mapa_sentidos = {}\n",
    "for i in range(len(num_agrupado)):\n",
    "    mapa_sentidos[numeros_agrupados[i]] = sentidos[i]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Lote                Data  Local  Faixa  Entrefaixa  Registro  \\\n",
       "30   L3 2018-03-01 00:00:12   5323      3           0         1   \n",
       "31   L3 2018-03-01 00:00:14   5323      3           0         2   \n",
       "32   L3 2018-03-01 00:00:16   5323      3           0         3   \n",
       "33   L3 2018-03-01 00:00:17   5323      3           0         4   \n",
       "34   L3 2018-03-01 00:00:20   5323      3           0         5   \n",
       "\n",
       "    Tipo de Registro Especie Classe Comprimento Velocidade Ocupacao  \\\n",
       "30                 0       1      0         041        044    01830   \n",
       "31                 0       1      0         037        047    01538   \n",
       "32                 0       1      0         038        058    01338   \n",
       "33                 0       1      0         041        061    01305   \n",
       "34                 0       1      0         041        075    01084   \n",
       "\n",
       "    Indice de Minutos Numero Agrupado  \n",
       "30              84960           10488  \n",
       "31              84960           10488  \n",
       "32              84960           10488  \n",
       "33              84960           10488  \n",
       "34              84960           10488  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Lote</th>\n      <th>Data</th>\n      <th>Local</th>\n      <th>Faixa</th>\n      <th>Entrefaixa</th>\n      <th>Registro</th>\n      <th>Tipo de Registro</th>\n      <th>Especie</th>\n      <th>Classe</th>\n      <th>Comprimento</th>\n      <th>Velocidade</th>\n      <th>Ocupacao</th>\n      <th>Indice de Minutos</th>\n      <th>Numero Agrupado</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>30</th>\n      <td>L3</td>\n      <td>2018-03-01 00:00:12</td>\n      <td>5323</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>041</td>\n      <td>044</td>\n      <td>01830</td>\n      <td>84960</td>\n      <td>10488</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>L3</td>\n      <td>2018-03-01 00:00:14</td>\n      <td>5323</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>037</td>\n      <td>047</td>\n      <td>01538</td>\n      <td>84960</td>\n      <td>10488</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>L3</td>\n      <td>2018-03-01 00:00:16</td>\n      <td>5323</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>038</td>\n      <td>058</td>\n      <td>01338</td>\n      <td>84960</td>\n      <td>10488</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>L3</td>\n      <td>2018-03-01 00:00:17</td>\n      <td>5323</td>\n      <td>3</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>041</td>\n      <td>061</td>\n      <td>01305</td>\n      <td>84960</td>\n      <td>10488</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>L3</td>\n      <td>2018-03-01 00:00:20</td>\n      <td>5323</td>\n      <td>3</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>041</td>\n      <td>075</td>\n      <td>01084</td>\n      <td>84960</td>\n      <td>10488</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "df_base = pd.read_csv(r'D:\\Users\\guilh\\Documents\\GitHub\\Dados_CET\\csv_radares-20200426T211130Z-001_selecionados/'+\"01_selecionado.csv\", index_col=[\"Unnamed: 0\"], parse_dates=True, dayfirst= True)\n",
    "\n",
    "# cria a coluna de numeros agrupados\n",
    "df_base['Numero Agrupado'] = df_base['Local'].map(faz_dict(Radares,num_agrupado))\n",
    "\n",
    "\n",
    "#coloca a Data e datetime object para facilitar manipulacao\n",
    "df_base[\"Data\"] = pd.to_datetime(df_base[\"Data\"],format='%Y-%d-%m %H:%M:%S', errors='coerce')\n",
    "\n",
    "\n",
    "df_base = df_base[df_base.Data.dt.day == 1]\n",
    "df_base.head()"
   ]
  },
  {
   "source": [
    "## Limpeza inicial do df\n",
    "\n",
    "* tiramos os NaNs, \n",
    "* os vazios,\n",
    "* adicionamos o Numero agrupado (str),\n",
    "* Coloca data em datetime,\n",
    "* Cria as colunas \"Numero Agrupado\", \"Dia_Sem\""
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  Lote                Data  Dia_Sem  Local Numero Agrupado  Faixa  Entrefaixa  \\\n",
       "0   L3 2018-03-01 00:00:12        3   5323           10488      3           0   \n",
       "1   L3 2018-03-01 00:00:14        3   5323           10488      3           0   \n",
       "2   L3 2018-03-01 00:00:16        3   5323           10488      3           0   \n",
       "3   L3 2018-03-01 00:00:17        3   5323           10488      3           0   \n",
       "4   L3 2018-03-01 00:00:20        3   5323           10488      3           0   \n",
       "\n",
       "   Registro  Tipo de Registro  Especie Classe Comprimento  Velocidade  \\\n",
       "0         1                 0        1      0         041          44   \n",
       "1         2                 0        1      0         037          47   \n",
       "2         3                 0        1      0         038          58   \n",
       "3         4                 0        1      0         041          61   \n",
       "4         5                 0        1      0         041          75   \n",
       "\n",
       "   Ocupacao  \n",
       "0    1830.0  \n",
       "1    1538.0  \n",
       "2    1338.0  \n",
       "3    1305.0  \n",
       "4    1084.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Lote</th>\n      <th>Data</th>\n      <th>Dia_Sem</th>\n      <th>Local</th>\n      <th>Numero Agrupado</th>\n      <th>Faixa</th>\n      <th>Entrefaixa</th>\n      <th>Registro</th>\n      <th>Tipo de Registro</th>\n      <th>Especie</th>\n      <th>Classe</th>\n      <th>Comprimento</th>\n      <th>Velocidade</th>\n      <th>Ocupacao</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>L3</td>\n      <td>2018-03-01 00:00:12</td>\n      <td>3</td>\n      <td>5323</td>\n      <td>10488</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>041</td>\n      <td>44</td>\n      <td>1830.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>L3</td>\n      <td>2018-03-01 00:00:14</td>\n      <td>3</td>\n      <td>5323</td>\n      <td>10488</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>037</td>\n      <td>47</td>\n      <td>1538.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>L3</td>\n      <td>2018-03-01 00:00:16</td>\n      <td>3</td>\n      <td>5323</td>\n      <td>10488</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>038</td>\n      <td>58</td>\n      <td>1338.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>L3</td>\n      <td>2018-03-01 00:00:17</td>\n      <td>3</td>\n      <td>5323</td>\n      <td>10488</td>\n      <td>3</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>041</td>\n      <td>61</td>\n      <td>1305.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>L3</td>\n      <td>2018-03-01 00:00:20</td>\n      <td>3</td>\n      <td>5323</td>\n      <td>10488</td>\n      <td>3</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>041</td>\n      <td>75</td>\n      <td>1084.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "\n",
    "# cria a coluna do dia da semana\n",
    "# ###############IMPORTANTE############# segunda = 0\n",
    "df_base[\"Dia_Sem\"] =  df_base[\"Data\"].dt.dayofweek\n",
    "\n",
    "\n",
    "########## UPDATE ###########\n",
    "# transforma todos radares 5479 na faixa 3, (5479,3) em radares 5478 na faixa 3 (5478,3)\n",
    "# pode ficar tranquilo por que eles tem o mesmo numero agrupado\n",
    "df_base.loc[(df_base[\"Local\"]==5479) & (df_base[\"Faixa\"] == 3), \"Local\"] = 5478\n",
    "\n",
    "# limpa a ocupacao\n",
    "df_base.drop(df_base.loc[df_base['Ocupacao'] =='     ','Ocupacao'].index, inplace=True)\n",
    "df_base.Ocupacao = df_base.Ocupacao.astype(float)\n",
    "\n",
    "#dropa vazios\n",
    "df_base.drop(df_base.loc[df_base['Velocidade'] =='   ','Velocidade'].index, inplace=True)\n",
    "\n",
    "#dropa não válidos (nan)\n",
    "df_base.loc[:,'Velocidade'].dropna(inplace=True)\n",
    "\n",
    "#coloca tudo no mesmo formato de dado int\n",
    "df_base.loc[:,'Velocidade'] = pd.to_numeric(df_base.loc[:,'Velocidade'])\n",
    "\n",
    "# colocar faixa no formato int\n",
    "df_base.loc[:,'Faixa'] = pd.to_numeric(df_base.loc[:,'Faixa'])\n",
    "\n",
    "# colocar Especie no formato int\n",
    "df_base.loc[:,'Especie'] = pd.to_numeric(df_base.loc[:,'Especie'])\n",
    "\n",
    "###### Numero Agrupado é uma String\n",
    "\n",
    "df_base.reset_index(drop=True,inplace=True)\n",
    "\n",
    "\n",
    "df_base = df_base[['Lote', 'Data', \"Dia_Sem\", 'Local', 'Numero Agrupado', 'Faixa', 'Entrefaixa',\n",
    "       'Registro', 'Tipo de Registro', 'Especie',\n",
    "      'Classe', 'Comprimento', 'Velocidade', 'Ocupacao']]\n",
    "df_base.head()"
   ]
  },
  {
   "source": [
    "## Cria o df agrupado\n",
    "\n",
    "df agrupado a cada 5 minutos\n",
    "adiciona Volume, velocidade media, mediana e desvio padrao\n",
    "adiciona ocupação media mediana e desvio padrao\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  Numero Agrupado  Faixa  Especie                Data  Dia_Sem  Volume  \\\n",
       "0           10488      1        0 2018-03-01 08:20:00        3       1   \n",
       "1           10488      1        0 2018-03-01 08:35:00        3       1   \n",
       "2           10488      1        0 2018-03-01 09:25:00        3       1   \n",
       "3           10488      1        0 2018-03-01 10:10:00        3       1   \n",
       "4           10488      1        0 2018-03-01 10:25:00        3       2   \n",
       "\n",
       "   Vel_media  Vel_mediana  Vel_desvpad  Ocu_media  Ocu_mediana  Ocu_desvpad  \n",
       "0       83.0         83.0          NaN      643.0        643.0          NaN  \n",
       "1       19.0         19.0          NaN     2314.0       2314.0          NaN  \n",
       "2       94.0         94.0          NaN      378.0        378.0          NaN  \n",
       "3       86.0         86.0          NaN      526.0        526.0          NaN  \n",
       "4      286.0        286.0   318.198052      412.5        412.5   482.953932  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Numero Agrupado</th>\n      <th>Faixa</th>\n      <th>Especie</th>\n      <th>Data</th>\n      <th>Dia_Sem</th>\n      <th>Volume</th>\n      <th>Vel_media</th>\n      <th>Vel_mediana</th>\n      <th>Vel_desvpad</th>\n      <th>Ocu_media</th>\n      <th>Ocu_mediana</th>\n      <th>Ocu_desvpad</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10488</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2018-03-01 08:20:00</td>\n      <td>3</td>\n      <td>1</td>\n      <td>83.0</td>\n      <td>83.0</td>\n      <td>NaN</td>\n      <td>643.0</td>\n      <td>643.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10488</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2018-03-01 08:35:00</td>\n      <td>3</td>\n      <td>1</td>\n      <td>19.0</td>\n      <td>19.0</td>\n      <td>NaN</td>\n      <td>2314.0</td>\n      <td>2314.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10488</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2018-03-01 09:25:00</td>\n      <td>3</td>\n      <td>1</td>\n      <td>94.0</td>\n      <td>94.0</td>\n      <td>NaN</td>\n      <td>378.0</td>\n      <td>378.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10488</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2018-03-01 10:10:00</td>\n      <td>3</td>\n      <td>1</td>\n      <td>86.0</td>\n      <td>86.0</td>\n      <td>NaN</td>\n      <td>526.0</td>\n      <td>526.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10488</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2018-03-01 10:25:00</td>\n      <td>3</td>\n      <td>2</td>\n      <td>286.0</td>\n      <td>286.0</td>\n      <td>318.198052</td>\n      <td>412.5</td>\n      <td>412.5</td>\n      <td>482.953932</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "df_agregado = df_base.copy()\n",
    "\n",
    "df_agregado.loc[:,'V1'] = df_agregado.loc[:,'Velocidade'].copy()\n",
    "df_agregado.loc[:,'V2'] = df_agregado.loc[:,'Velocidade'].copy()\n",
    "df_agregado.loc[:,'Oc1'] = df_agregado.loc[:,'Ocupacao'].copy()\n",
    "df_agregado.loc[:,'Oc2'] = df_agregado.loc[:,'Ocupacao'].copy()\n",
    "df_agregado = df_agregado.groupby([ 'Numero Agrupado',\"Faixa\",'Especie',pd.Grouper(key='Data', freq='5Min')]).agg({'Dia_Sem': \"mean\",\n",
    "                                                                        \"Registro\": \"count\",\n",
    "                                                                        'Velocidade': 'mean',\n",
    "                                                                        'V1':'median',\n",
    "                                                                        'V2':'std',\n",
    "                                                                        'Ocupacao':'mean',\n",
    "                                                                        'Oc1':'median',\n",
    "                                                                        'Oc2':'std',\n",
    "                                                                        })\n",
    "df_agregado.columns=['Dia_Sem',\n",
    "            \"Volume\",\n",
    "            'Vel_media',\n",
    "            'Vel_mediana',\n",
    "            'Vel_desvpad',\n",
    "            'Ocu_media',\n",
    "            'Ocu_mediana',\n",
    "            'Ocu_desvpad'\n",
    "            ] # Renomeia\n",
    "\n",
    "df_agregado.reset_index(inplace=True)\n",
    "df_agregado.head()"
   ]
  },
  {
   "source": [
    "## Criando dicionarios\n",
    "\n",
    "Aqui são dicionarios que serão utilizados para gerar colunas via mapeamento"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "17"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                 Data  Dia_Sem Periodo Numero Agrupado  Faixa NumAg_fx  \\\n0 2018-03-01 08:20:00        3      P3           10488      1   104881   \n1 2018-03-01 08:35:00        3      P3           10488      1   104881   \n2 2018-03-01 09:25:00        3      P3           10488      1   104881   \n3 2018-03-01 10:10:00        3      P4           10488      1   104881   \n4 2018-03-01 10:25:00        3      P4           10488      1   104881   \n\n  Fx_tipo        Eixo  Especie  Volume  Vel_media  Vel_mediana  Vel_desvpad  \\\n0  onibus  23deMaio_B        0       1       83.0         83.0          NaN   \n1  onibus  23deMaio_B        0       1       19.0         19.0          NaN   \n2  onibus  23deMaio_B        0       1       94.0         94.0          NaN   \n3  onibus  23deMaio_B        0       1       86.0         86.0          NaN   \n4  onibus  23deMaio_B        0       2      286.0        286.0   318.198052   \n\n   Ocu_media  Ocu_mediana  Ocu_desvpad Estacao Meteorol  \n0      643.0        643.0          NaN              CGE  \n1     2314.0       2314.0          NaN              CGE  \n2      378.0        378.0          NaN              CGE  \n3      526.0        526.0          NaN              CGE  \n4      412.5        412.5   482.953932              CGE  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Data</th>\n      <th>Dia_Sem</th>\n      <th>Periodo</th>\n      <th>Numero Agrupado</th>\n      <th>Faixa</th>\n      <th>NumAg_fx</th>\n      <th>Fx_tipo</th>\n      <th>Eixo</th>\n      <th>Especie</th>\n      <th>Volume</th>\n      <th>Vel_media</th>\n      <th>Vel_mediana</th>\n      <th>Vel_desvpad</th>\n      <th>Ocu_media</th>\n      <th>Ocu_mediana</th>\n      <th>Ocu_desvpad</th>\n      <th>Estacao Meteorol</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018-03-01 08:20:00</td>\n      <td>3</td>\n      <td>P3</td>\n      <td>10488</td>\n      <td>1</td>\n      <td>104881</td>\n      <td>onibus</td>\n      <td>23deMaio_B</td>\n      <td>0</td>\n      <td>1</td>\n      <td>83.0</td>\n      <td>83.0</td>\n      <td>NaN</td>\n      <td>643.0</td>\n      <td>643.0</td>\n      <td>NaN</td>\n      <td>CGE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018-03-01 08:35:00</td>\n      <td>3</td>\n      <td>P3</td>\n      <td>10488</td>\n      <td>1</td>\n      <td>104881</td>\n      <td>onibus</td>\n      <td>23deMaio_B</td>\n      <td>0</td>\n      <td>1</td>\n      <td>19.0</td>\n      <td>19.0</td>\n      <td>NaN</td>\n      <td>2314.0</td>\n      <td>2314.0</td>\n      <td>NaN</td>\n      <td>CGE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-03-01 09:25:00</td>\n      <td>3</td>\n      <td>P3</td>\n      <td>10488</td>\n      <td>1</td>\n      <td>104881</td>\n      <td>onibus</td>\n      <td>23deMaio_B</td>\n      <td>0</td>\n      <td>1</td>\n      <td>94.0</td>\n      <td>94.0</td>\n      <td>NaN</td>\n      <td>378.0</td>\n      <td>378.0</td>\n      <td>NaN</td>\n      <td>CGE</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2018-03-01 10:10:00</td>\n      <td>3</td>\n      <td>P4</td>\n      <td>10488</td>\n      <td>1</td>\n      <td>104881</td>\n      <td>onibus</td>\n      <td>23deMaio_B</td>\n      <td>0</td>\n      <td>1</td>\n      <td>86.0</td>\n      <td>86.0</td>\n      <td>NaN</td>\n      <td>526.0</td>\n      <td>526.0</td>\n      <td>NaN</td>\n      <td>CGE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2018-03-01 10:25:00</td>\n      <td>3</td>\n      <td>P4</td>\n      <td>10488</td>\n      <td>1</td>\n      <td>104881</td>\n      <td>onibus</td>\n      <td>23deMaio_B</td>\n      <td>0</td>\n      <td>2</td>\n      <td>286.0</td>\n      <td>286.0</td>\n      <td>318.198052</td>\n      <td>412.5</td>\n      <td>412.5</td>\n      <td>482.953932</td>\n      <td>CGE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "\n",
    "# Criando a coluna Periodo (no lugar de y pode ser qualquer coisa, menos numero)\n",
    "df_agregado[\"Periodo\"] = \"y\"\n",
    "\n",
    "\n",
    "df_agregado['aux'] = pd.cut(np.array(df_agregado.Data.dt.hour), intervalos)\n",
    "\n",
    "try:\n",
    "    df_agregado['aux'] = df_agregado['aux'].astype(str)\n",
    "    df_agregado['Periodo'] = df_agregado['aux'].map(mapa_intervalos)\n",
    "    df_agregado.drop(columns=[\"aux\"],inplace=True, axis = 0)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Criando a colua Eixo usando o mapa de sentidos das vias criado acimma\n",
    "df_agregado[\"Eixo\"] = df_agregado[\"Numero Agrupado\"].map(mapa_sentidos)\n",
    "\n",
    "# Criando a coluna Numero agregado + faixa, somando as strings\n",
    "df_agregado[\"NumAg_fx\"] = df_agregado[\"Numero Agrupado\"] + df_agregado['Faixa'].astype(str)\n",
    "\n",
    "# Criando a coluna Faixa tipo que, para cada NumAg_fx determina qual o tipo de faixa\n",
    "df_agregado[\"Fx_tipo\"] = df_agregado[\"NumAg_fx\"].map(mapfaixas)\n",
    "\n",
    "#criando coluna de estação meteorologica, será retirada mais a frente\n",
    "df_agregado['Estacao Meteorol'] = df_agregado[\"Numero Agrupado\"].map(mapa_estacoes)\n",
    "\n",
    "\n",
    "# reorganiza a ordem das colunas\n",
    "df_agregado = df_agregado[[\"Data\", \"Dia_Sem\", \"Periodo\", \"Numero Agrupado\", \"Faixa\", \"NumAg_fx\",\"Fx_tipo\",\"Eixo\",\"Especie\",\"Volume\", \"Vel_media\", \"Vel_mediana\", \"Vel_desvpad\", \"Ocu_media\", \"Ocu_mediana\", \"Ocu_desvpad\", 'Estacao Meteorol']] # 17 sao as que vao ficar, mas ai tem 18\n",
    "\n",
    "\n",
    "\n",
    "display(df_agregado.shape[1], df_agregado.head())\n"
   ]
  },
  {
   "source": [
    "### ate aqui temos 17 colunas finais\n",
    "\n",
    "Foram adicionadas o \n",
    "\n",
    "* Período\n",
    "* Eixo\n",
    "* NumAg_fx\n",
    "* Fx_tipo\n",
    "* Estacao Meteorol"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to fazendo pra um radar de exemplo mas preciso fazer o mesmo processo para\n",
    "# cada numero agrupado\n",
    "# cada Especie\n",
    "# Cada Faixa\n",
    "# 24 horas do dia * 60 minutos por hora / 5 minutos = 288 registros por cada um dos \n",
    "# 288 * 4 especies * 3 faixas(em media) = 3456 por numero agrupado\n",
    "# 3456 * 34 Num agrup = 117.504 linhas por dia\n",
    "# 117504 * 30 dias = 35 milhoes\n",
    "# por dia ate que nao esta muito nao, é um tamanho parecido com o DF que entra\n",
    "\n",
    "# radar10680 = df_agregado.loc[(df_agregado[\"Numero Agrupado\"] == \"10468\")\n",
    "#             &   (df_agregado[\"Faixa\"] == 1)\n",
    "#             &   (df_agregado[\"Especie\"] == \"1\")\n",
    "\n",
    "#                 ].sort_values(by=\"Data\")\n",
    "\n",
    "# radar10680 = radar10680.set_index(\"Data\").asfreq(\"5 min\")\n",
    "\n",
    "# radar10680[[\"Numero Agrupado\",\"Faixa\",\"Especie\",\"Dia_Sem\",\"NumAg_fx\",\"Fx_tipo\",\"Eixo\"]] = radar10680[[\"Numero Agrupado\",\"Faixa\",\"Especie\",\"Dia_Sem\",\"NumAg_fx\", \"Fx_tipo\",\t\"Eixo\"]].fillna(method=\"ffill\")\n",
    "\n",
    "# radar10680.head()\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Adiciona as colunas de chuva\n",
    "\n",
    "A depender do qual radar estamos tratando, usamos uma estação meteorológica para computar os dados de chuva por 5 minutos\n",
    "\n",
    "O timedelta faz o trabalho de defasar o df da chuva para ficar alinhado com o df_agregado "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 DATA  JB  VM  CGE  ST  PI  IP  BT  LA  SA\n",
       "0 2018-02-28 23:55:00   0   0    0   0   0   0   0   0   0\n",
       "1 2018-03-01 00:00:00   0   0    0   0   0   0   0   0   0\n",
       "2 2018-03-01 00:05:00   0   0    0   0   0   0   0   0   0\n",
       "3 2018-03-01 00:10:00   0   0    0   0   0   0   0   0   0\n",
       "4 2018-03-01 00:15:00   0   0    0   0   0   0   0   0   0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DATA</th>\n      <th>JB</th>\n      <th>VM</th>\n      <th>CGE</th>\n      <th>ST</th>\n      <th>PI</th>\n      <th>IP</th>\n      <th>BT</th>\n      <th>LA</th>\n      <th>SA</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018-02-28 23:55:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018-03-01 00:00:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-03-01 00:05:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2018-03-01 00:10:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2018-03-01 00:15:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "chuva = pd.read_excel(r\"D:\\Users\\guilh\\Documents\\[POLI]_6_Semestre\\IC\\2021\\codigos olimpio\\Radar X Chuva.xlsx\", sheet_name = \"Chuva\", parse_dates=True)\n",
    "chuva[\"DATA\"] = pd.to_datetime(chuva[\"DATA\"],format='%Y-%d-%m %H:%M:%S', errors='coerce').astype(\"datetime64[s]\")\n",
    "chuva = chuva[chuva.DATA.dt.month == 3]\n",
    "\n",
    "chuva[\"DATA\"] = chuva[\"DATA\"] -timedelta(minutes = 5)\n",
    "\n",
    "for estacao in [\"JB\",\"CGE\",\"ST\",\"PI\",\"BT\", \"IP\",\"LA\",\"SA\"]: \n",
    "    chuva[estacao] = pd.to_numeric(chuva[estacao])\n",
    "\n",
    "\n",
    "chuva.reset_index(drop=True, inplace=True)\n",
    "\n",
    "chuva.head()\n"
   ]
  },
  {
   "source": [
    "aqui tem um pequeno exemplo caso queira computar para apenas um radar, sem iterações"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_radar10680 = radar10680.merge(chuva[[\"DATA\", \"CGE\"]],how=\"left\",right_on= \"DATA\", left_on=\"Data\")\n",
    "\n",
    "# merged_radar10680[\"Chuva 1h\"] = merged_radar10680[\"CGE\"].rolling(12).sum()\n",
    "\n",
    "# merged_radar10680 = merged_radar10680 [[\"DATA\", \"Dia_Sem\", \"Periodo\", \"Numero Agrupado\", \"Faixa\", \"NumAg_fx\",\"Fx_tipo\",\"Eixo\",\"Especie\",\"Volume\", \"Vel_media\", \"Vel_mediana\", \"Vel_desvpad\", \"Ocu_media\", \"Ocu_mediana\", \"Ocu_desvpad\", \"CGE\", \"Chuva 1h\"]]\n",
    "\n",
    "# merged_radar10680.columns = [\"Data\", \"Dia_Sem\", \"Periodo\", \"Numero Agrupado\", \"Faixa\", \"NumAg_fx\",\"Fx_tipo\",\"Eixo\",\"Especie\",\"Volume\", \"Vel_media\", \"Vel_mediana\", \"Vel_desvpad\", \"Ocu_media\", \"Ocu_mediana\", \"Ocu_desvpad\", \"Chuva\", \"Chuva 1h\"]\n",
    "\n",
    "\n",
    "# merged_radar10680.head()"
   ]
  },
  {
   "source": [
    "# Iteração para todos os radares"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "radar: 10488      Especie 0       Faixa: 5      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10488      Especie 0       Faixa: 6      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10488      Especie 1       Faixa: 5      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10488      Especie 1       Faixa: 6      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10488      Especie 2       Faixa: 5      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10488      Especie 2       Faixa: 6      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10488      Especie 3       Faixa: 5      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10488      Especie 3       Faixa: 6      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10582      Especie 0       Faixa: 1      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10582      Especie 0       Faixa: 2      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10582      Especie 0       Faixa: 3      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10582      Especie 0       Faixa: 4      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10582      Especie 0       Faixa: 5      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10582      Especie 0       Faixa: 6      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10582      Especie 1       Faixa: 1      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10582      Especie 1       Faixa: 2      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10582      Especie 1       Faixa: 3      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10582      Especie 1       Faixa: 4      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10582      Especie 1       Faixa: 5      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10582      Especie 1       Faixa: 6      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10582      Especie 2       Faixa: 1      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10582      Especie 2       Faixa: 2      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10582      Especie 2       Faixa: 3      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10582      Especie 2       Faixa: 4      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10582      Especie 2       Faixa: 5      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10582      Especie 2       Faixa: 6      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10582      Especie 3       Faixa: 1      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10582      Especie 3       Faixa: 2      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10582      Especie 3       Faixa: 3      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10582      Especie 3       Faixa: 4      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10582      Especie 3       Faixa: 5      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10582      Especie 3       Faixa: 6      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10514      Especie 0       Faixa: 1      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10514      Especie 0       Faixa: 2      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10514      Especie 0       Faixa: 3      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10514      Especie 0       Faixa: 4      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10514      Especie 0       Faixa: 5      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10514      Especie 0       Faixa: 6      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10514      Especie 1       Faixa: 1      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10514      Especie 1       Faixa: 2      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10514      Especie 1       Faixa: 3      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10514      Especie 1       Faixa: 4      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10514      Especie 1       Faixa: 5      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10514      Especie 1       Faixa: 6      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10514      Especie 2       Faixa: 1      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10514      Especie 2       Faixa: 2      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10514      Especie 2       Faixa: 3      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10514      Especie 2       Faixa: 4      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10514      Especie 2       Faixa: 5      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10514      Especie 2       Faixa: 6      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10514      Especie 3       Faixa: 1      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10514      Especie 3       Faixa: 2      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10514      Especie 3       Faixa: 3      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10514      Especie 3       Faixa: 4      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10514      Especie 3       Faixa: 5      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10514      Especie 3       Faixa: 6      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10513      Especie 0       Faixa: 1      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10513      Especie 0       Faixa: 2      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10513      Especie 0       Faixa: 3      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10513      Especie 0       Faixa: 4      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10513      Especie 0       Faixa: 5      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10513      Especie 0       Faixa: 6      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10513      Especie 1       Faixa: 1      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10513      Especie 1       Faixa: 2      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10513      Especie 1       Faixa: 3      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10513      Especie 1       Faixa: 4      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10513      Especie 1       Faixa: 5      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10513      Especie 1       Faixa: 6      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10513      Especie 2       Faixa: 1      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10513      Especie 2       Faixa: 2      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10513      Especie 2       Faixa: 3      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10513      Especie 2       Faixa: 4      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10513      Especie 2       Faixa: 5      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10513      Especie 2       Faixa: 6      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10513      Especie 3       Faixa: 1      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10513      Especie 3       Faixa: 2      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10513      Especie 3       Faixa: 3      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10513      Especie 3       Faixa: 4      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10513      Especie 3       Faixa: 5      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10513      Especie 3       Faixa: 6      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10587      Especie 0       Faixa: 1      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10587      Especie 0       Faixa: 2      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10587      Especie 0       Faixa: 3      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10587      Especie 0       Faixa: 4      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10587      Especie 0       Faixa: 5      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10587      Especie 0       Faixa: 6      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10587      Especie 1       Faixa: 1      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10587      Especie 1       Faixa: 2      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10587      Especie 1       Faixa: 3      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10587      Especie 1       Faixa: 4      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10587      Especie 1       Faixa: 5      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10587      Especie 1       Faixa: 6      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10587      Especie 2       Faixa: 1      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10587      Especie 2       Faixa: 2      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10587      Especie 2       Faixa: 3      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10587      Especie 2       Faixa: 4      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10587      Especie 2       Faixa: 5      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10587      Especie 2       Faixa: 6      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10587      Especie 3       Faixa: 1      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10587      Especie 3       Faixa: 2      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10587      Especie 3       Faixa: 3      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10587      Especie 3       Faixa: 4      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10587      Especie 3       Faixa: 5      //        radar,faixa ou especie nao presente no dataframe\n",
      "radar: 10587      Especie 3       Faixa: 6      //        radar,faixa ou especie nao presente no dataframe\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame()\n",
    "df_reduzido = df_agregado.copy()\n",
    "\n",
    "# for radar in list(set(df_agregado[\"Numero Agrupado\"])):\n",
    "\n",
    "\n",
    "# caso queira testar para so alguns radares\n",
    "for radar in [\"10488\", '10582', '10514', '10513', '10587']:\n",
    "\n",
    "\n",
    "    for especie in list(set(df_reduzido[\"Especie\"])):\n",
    "\n",
    "\n",
    "        for faixa in list(set(df_reduzido[\"Faixa\"])):\n",
    "            \n",
    "            # faz um pequeno subset do df buscando criar uma configuração de radar, faixa e especie especifica\n",
    "            radar_especifico = df_reduzido.loc[(df_reduzido[\"Numero Agrupado\"] == radar)\n",
    "                                            &   (df_reduzido[\"Especie\"] == especie)\n",
    "                                            &   (df_reduzido[\"Faixa\"] == faixa)].sort_values(by=\"Data\").reset_index(drop=True)\n",
    "      \n",
    "            \n",
    "            #adiciona linhas nos intervalos de 5 minutos que nao tem registro de veiculo, portanto, linhas vazias\n",
    "            radar_especifico = radar_especifico.set_index(\"Data\").asfreq(\"5 min\")\n",
    "\n",
    "            #o seguinte preenchimento deve ser feito apos as novas linhas de 5 minutos que\n",
    "            # que nao tem registros serem adicionadas, e \n",
    "            # somente nas colunas selecionadas, que sao as que sabemos os parametros\n",
    "\n",
    "            colunas_preenchiveis = [\"Numero Agrupado\",\"Faixa\",\"Especie\",\"Dia_Sem\",\"NumAg_fx\",\"Fx_tipo\",\"Eixo\", \"Periodo\", \"Estacao Meteorol\"]\n",
    "            radar_especifico[colunas_preenchiveis] = radar_especifico[colunas_preenchiveis].fillna(method=\"ffill\")\n",
    "\n",
    "            #o metodo de preenchimento é forward fill, o NaN é preenchido com o conteudo de cima\n",
    "            # poderia ser backward fill (backfill) ja que para essas colunas nao faz diferença\n",
    "\n",
    "\n",
    "            # esse try existe para que seja possivel rodar o codigo mesmo que um radar nao esteja no arquivo \n",
    "            try:\n",
    "                # seleciona qual é a estação meteorologica para esse radar especifico\n",
    "                estac_metero = radar_especifico[\"Estacao Meteorol\"][0]\n",
    "\n",
    "                # merge entre as duas tabelas, com prevalencia da tabela de radares (left)\n",
    "                radar_com_chuva = radar_especifico.merge(chuva[[\"DATA\", estac_metero]],how=\"left\",right_on= \"DATA\", left_on=\"Data\")\n",
    "\n",
    "                # Cria a coluna com a soma rolante da ultima hora (por isso os ultimos 12 registros)\n",
    "                radar_com_chuva[\"Chuva 1h\"] = radar_com_chuva[\"CGE\"].rolling(12).sum()\n",
    "\n",
    "                # reorganiza a ordem das colunas\n",
    "                radar_com_chuva = radar_com_chuva [[\"DATA\", \"Dia_Sem\", \"Periodo\", \"Numero Agrupado\", \"Faixa\", \"NumAg_fx\",\"Fx_tipo\",\"Eixo\",\"Especie\",\"Volume\", \"Vel_media\", \"Vel_mediana\", \"Vel_desvpad\", \"Ocu_media\", \"Ocu_mediana\", \"Ocu_desvpad\", estac_metero, \"Chuva 1h\"]]\n",
    "\n",
    "                # reorganiza o nome das colunas\n",
    "                radar_com_chuva.columns = [\"Data\", \"Dia_Sem\", \"Periodo\", \"Numero Agrupado\", \"Faixa\", \"NumAg_fx\",\"Fx_tipo\",\"Eixo\",\"Especie\",\"Volume\", \"Vel_media\", \"Vel_mediana\", \"Vel_desvpad\", \"Ocu_media\", \"Ocu_mediana\", \"Ocu_desvpad\", \"Chuva_5min\", \"Chuva_1h\"]\n",
    "\n",
    "                #concatena os dataframes em uma unica tabela\n",
    "                df = pd.concat([df, radar_com_chuva])\n",
    "            except:\n",
    "                print(\"radar:\",radar, \"     Especie\",especie,\"      Faixa:\",faixa,\"     //        radar,faixa ou especie nao presente no dataframe\")\n",
    "\n",
    "\n",
    "# df.to_excel(\"tabela nova.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                   Data  Dia_Sem Periodo Numero Agrupado  Faixa NumAg_fx  \\\n",
       "0   2018-03-01 08:20:00      3.0      P3           10488    1.0   104881   \n",
       "1   2018-03-01 08:25:00      3.0      P3           10488    1.0   104881   \n",
       "2   2018-03-01 08:30:00      3.0      P3           10488    1.0   104881   \n",
       "3   2018-03-01 08:35:00      3.0      P3           10488    1.0   104881   \n",
       "4   2018-03-01 08:40:00      3.0      P3           10488    1.0   104881   \n",
       "..                  ...      ...     ...             ...    ...      ...   \n",
       "137 2018-03-01 23:30:00      3.0      P7           10488    4.0   104884   \n",
       "138 2018-03-01 23:35:00      3.0      P7           10488    4.0   104884   \n",
       "139 2018-03-01 23:40:00      3.0      P7           10488    4.0   104884   \n",
       "140 2018-03-01 23:45:00      3.0      P7           10488    4.0   104884   \n",
       "141 2018-03-01 23:50:00      3.0      P7           10488    4.0   104884   \n",
       "\n",
       "    Fx_tipo        Eixo  Especie  Volume  Vel_media  Vel_mediana  Vel_desvpad  \\\n",
       "0    onibus  23deMaio_B      0.0     1.0       83.0         83.0          NaN   \n",
       "1    onibus  23deMaio_B      0.0     NaN        NaN          NaN          NaN   \n",
       "2    onibus  23deMaio_B      0.0     NaN        NaN          NaN          NaN   \n",
       "3    onibus  23deMaio_B      0.0     1.0       19.0         19.0          NaN   \n",
       "4    onibus  23deMaio_B      0.0     NaN        NaN          NaN          NaN   \n",
       "..      ...         ...      ...     ...        ...          ...          ...   \n",
       "137   mista  23deMaio_B      3.0     NaN        NaN          NaN          NaN   \n",
       "138   mista  23deMaio_B      3.0     NaN        NaN          NaN          NaN   \n",
       "139   mista  23deMaio_B      3.0     NaN        NaN          NaN          NaN   \n",
       "140   mista  23deMaio_B      3.0     1.0       94.0         94.0          NaN   \n",
       "141   mista  23deMaio_B      3.0     1.0       83.0         83.0          NaN   \n",
       "\n",
       "     Ocu_media  Ocu_mediana  Ocu_desvpad  Chuva_5min  Chuva_1h  \n",
       "0        643.0        643.0          NaN           0       NaN  \n",
       "1          NaN          NaN          NaN           0       NaN  \n",
       "2          NaN          NaN          NaN           0       NaN  \n",
       "3       2314.0       2314.0          NaN           0       NaN  \n",
       "4          NaN          NaN          NaN           0       NaN  \n",
       "..         ...          ...          ...         ...       ...  \n",
       "137        NaN          NaN          NaN           0       0.0  \n",
       "138        NaN          NaN          NaN           0       0.0  \n",
       "139        NaN          NaN          NaN         250     250.0  \n",
       "140     1280.0       1280.0          NaN         250     500.0  \n",
       "141     1085.0       1085.0          NaN         250     750.0  \n",
       "\n",
       "[3169 rows x 18 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Data</th>\n      <th>Dia_Sem</th>\n      <th>Periodo</th>\n      <th>Numero Agrupado</th>\n      <th>Faixa</th>\n      <th>NumAg_fx</th>\n      <th>Fx_tipo</th>\n      <th>Eixo</th>\n      <th>Especie</th>\n      <th>Volume</th>\n      <th>Vel_media</th>\n      <th>Vel_mediana</th>\n      <th>Vel_desvpad</th>\n      <th>Ocu_media</th>\n      <th>Ocu_mediana</th>\n      <th>Ocu_desvpad</th>\n      <th>Chuva_5min</th>\n      <th>Chuva_1h</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018-03-01 08:20:00</td>\n      <td>3.0</td>\n      <td>P3</td>\n      <td>10488</td>\n      <td>1.0</td>\n      <td>104881</td>\n      <td>onibus</td>\n      <td>23deMaio_B</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>83.0</td>\n      <td>83.0</td>\n      <td>NaN</td>\n      <td>643.0</td>\n      <td>643.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018-03-01 08:25:00</td>\n      <td>3.0</td>\n      <td>P3</td>\n      <td>10488</td>\n      <td>1.0</td>\n      <td>104881</td>\n      <td>onibus</td>\n      <td>23deMaio_B</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-03-01 08:30:00</td>\n      <td>3.0</td>\n      <td>P3</td>\n      <td>10488</td>\n      <td>1.0</td>\n      <td>104881</td>\n      <td>onibus</td>\n      <td>23deMaio_B</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2018-03-01 08:35:00</td>\n      <td>3.0</td>\n      <td>P3</td>\n      <td>10488</td>\n      <td>1.0</td>\n      <td>104881</td>\n      <td>onibus</td>\n      <td>23deMaio_B</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>19.0</td>\n      <td>19.0</td>\n      <td>NaN</td>\n      <td>2314.0</td>\n      <td>2314.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2018-03-01 08:40:00</td>\n      <td>3.0</td>\n      <td>P3</td>\n      <td>10488</td>\n      <td>1.0</td>\n      <td>104881</td>\n      <td>onibus</td>\n      <td>23deMaio_B</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>137</th>\n      <td>2018-03-01 23:30:00</td>\n      <td>3.0</td>\n      <td>P7</td>\n      <td>10488</td>\n      <td>4.0</td>\n      <td>104884</td>\n      <td>mista</td>\n      <td>23deMaio_B</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>138</th>\n      <td>2018-03-01 23:35:00</td>\n      <td>3.0</td>\n      <td>P7</td>\n      <td>10488</td>\n      <td>4.0</td>\n      <td>104884</td>\n      <td>mista</td>\n      <td>23deMaio_B</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>139</th>\n      <td>2018-03-01 23:40:00</td>\n      <td>3.0</td>\n      <td>P7</td>\n      <td>10488</td>\n      <td>4.0</td>\n      <td>104884</td>\n      <td>mista</td>\n      <td>23deMaio_B</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>250</td>\n      <td>250.0</td>\n    </tr>\n    <tr>\n      <th>140</th>\n      <td>2018-03-01 23:45:00</td>\n      <td>3.0</td>\n      <td>P7</td>\n      <td>10488</td>\n      <td>4.0</td>\n      <td>104884</td>\n      <td>mista</td>\n      <td>23deMaio_B</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>94.0</td>\n      <td>94.0</td>\n      <td>NaN</td>\n      <td>1280.0</td>\n      <td>1280.0</td>\n      <td>NaN</td>\n      <td>250</td>\n      <td>500.0</td>\n    </tr>\n    <tr>\n      <th>141</th>\n      <td>2018-03-01 23:50:00</td>\n      <td>3.0</td>\n      <td>P7</td>\n      <td>10488</td>\n      <td>4.0</td>\n      <td>104884</td>\n      <td>mista</td>\n      <td>23deMaio_B</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>83.0</td>\n      <td>83.0</td>\n      <td>NaN</td>\n      <td>1085.0</td>\n      <td>1085.0</td>\n      <td>NaN</td>\n      <td>250</td>\n      <td>750.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3169 rows × 18 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}